{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IloveKOSA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-env-QISotLL5-py3.11\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"ai_sample_collection\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 개의 문서가 성공적으로 DB에 추가되었습니다.\n",
      "['doc_1', 'doc_2', 'doc_3', 'doc_4', 'doc_5']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 기술입니다.\",\n",
    "]\n",
    "\n",
    "doc_objects = []\n",
    "\n",
    "for i, content in enumerate(documents, start=1):\n",
    "    doc = Document(\n",
    "        page_content=content,\n",
    "        metadata={\"source\": \"AI_Textbook\", \"chapter\": f\"Chapter {i}\"}\n",
    "    )\n",
    "\n",
    "    doc_objects.append(doc)\n",
    "\n",
    "#순차적 ID 리스트 생성\n",
    "doc_ids = [f\"doc_{i}\" for i in range(1, len(doc_objects) + 1)]\n",
    "\n",
    "added_docs_ids = chroma_db.add_documents(documents = doc_objects, ids=doc_ids)\n",
    "\n",
    "print(f\"{len(added_docs_ids)} 개의 문서가 성공적으로 DB에 추가되었습니다.\")\n",
    "print(added_docs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 인공지능과 머신러닝의 관계는?\n",
      "문서 ID: Chapter 2, 내용: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "문서 ID: Chapter 3, 내용: 딥러닝은 머신러닝의 한 종류입니다.\n"
     ]
    }
   ],
   "source": [
    "query = \"인공지능과 머신러닝의 관계는?\"\n",
    "results = chroma_db.similarity_search(query, k=2) #관련 문서 k개 추출, 없으면 0도 가능\n",
    "\n",
    "print(f\"질문: {query}\")\n",
    "for doc in results:\n",
    "    print(f\"문서 ID: {doc.metadata['chapter']}, 내용: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc_1', 'doc_2', 'doc_3', 'doc_4', 'doc_5'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야입니다.',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.',\n",
       "  '컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 1', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 5', 'source': 'AI_Textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 업데이트 완료\n"
     ]
    }
   ],
   "source": [
    "# chroma_db.update_documents(document_ids=added_docs_ids, documents=doc_objects, document=doc_objects)\n",
    "# Document(page_content, metadata={})\n",
    "\n",
    "update_document_1 = Document(\n",
    "    page_content=\"인공지능은 컴퓨터 과학의 한 분야로, 머신러닝과 딥러닝을 포함합니다\",\n",
    "    metadata={\"source\": \"AI_Textbook\", \"chapter\": \"Chapter 6\"}\n",
    ")\n",
    "\n",
    "chroma_db.update_document(\n",
    "    document_id=\"doc_1\",\n",
    "    document=update_document_1\n",
    ")\n",
    "\n",
    "print(\"문서 업데이트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc_1', 'doc_2', 'doc_3', 'doc_4', 'doc_5'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야로, 머신러닝과 딥러닝을 포함합니다',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.',\n",
       "  '컴퓨터 비전은 컴퓨터가 디지털 이미지나 비디오를 이해하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 6', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 5', 'source': 'AI_Textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db.delete(ids=[\"doc_5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc_1', 'doc_2', 'doc_3', 'doc_4'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야로, 머신러닝과 딥러닝을 포함합니다',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 6', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_Textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['doc_1', 'doc_2', 'doc_3', 'doc_4'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['인공지능은 컴퓨터 과학의 한 분야로, 머신러닝과 딥러닝을 포함합니다',\n",
       "  '머신러닝은 인공지능의 하위 분야입니다.',\n",
       "  '딥러닝은 머신러닝의 한 종류입니다.',\n",
       "  '자연어 처리는 컴퓨터가 인간의 언어를 이해하고 생성하는 기술입니다.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'chapter': 'Chapter 6', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 2', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 3', 'source': 'AI_Textbook'},\n",
       "  {'chapter': 'Chapter 4', 'source': 'AI_Textbook'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db2 = Chroma(\n",
    "    collection_name=\"ai_sample_collection\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "chroma_db2.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문서 수:  8\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "def load_text_files(text_files):\n",
    "    data = []\n",
    "    for file in text_files:\n",
    "        loader = TextLoader(file, encoding=\"utf-8\")\n",
    "        data += loader.load()\n",
    "    \n",
    "    return data\n",
    "\n",
    "korean_text_files = glob(os.path.join(\"data\", \"*_KR.txt\"))\n",
    "korean_data = load_text_files(korean_text_files)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer = tokenizer,\n",
    "    separator = r\"[.!?]\\s+\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    "    is_separator_regex = True,\n",
    "    keep_separator = True,\n",
    ")\n",
    "\n",
    "\n",
    "korean_docs = text_splitter.split_documents(korean_data)\n",
    "\n",
    "print(\"한국어 문서 수: \", len(korean_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['ab931cdc-cbb7-44f4-87c9-072240e7c5de',\n",
       "  '4d1ec4d3-22fe-4eff-bacf-7dfef9d21a0b',\n",
       "  'ece0b64f-55bc-4079-8857-2caa71d46805',\n",
       "  '06558093-514c-4ad3-a63f-af6505a583aa',\n",
       "  '7e4ab40c-807a-4294-a9d1-5748b5bf3d34',\n",
       "  '646acb5d-71f6-4083-8faf-0bd8b192d3f3',\n",
       "  '44497e91-9d2d-48a7-9156-b90920184032',\n",
       "  '2ca8e234-6956-4ee4-b5ff-3d15acbc2afc'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다',\n",
       "  '.\\n\\n리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다',\n",
       "  '. 리비안은 디젤 하이브리드 버전, 브라질 원메이크 시리즈를 위한 R1 GT 레이싱 버전, 4도어 세단 및 크로스오버 등 다양한 버전을 고려했습니다. 2011년에 프로토타입 해치백도 공개되었지만, R1과의 관계는 불명확합니다',\n",
       "  '.\\n\\n리비안은 2021년 10월 첫 번째 양산 차량인 R1T 트럭을 고객에게 인도하기 시작했습니다.',\n",
       "  '테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다',\n",
       "  '. 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다',\n",
       "  '.\\n\\n2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년에 비해 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 테슬라의 전 세계 누적 판매량은 4,962,975대를 초과했습니다. SMT Packaging에 따르면, 2023년 테슬라의 판매량은 전 세계 전기차 시장의 약 12.9%를 차지했습니다',\n",
       "  '.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'source': 'data\\\\리비안_KR.txt'},\n",
       "  {'source': 'data\\\\리비안_KR.txt'},\n",
       "  {'source': 'data\\\\리비안_KR.txt'},\n",
       "  {'source': 'data\\\\리비안_KR.txt'},\n",
       "  {'source': 'data\\\\테슬라_KR.txt'},\n",
       "  {'source': 'data\\\\테슬라_KR.txt'},\n",
       "  {'source': 'data\\\\테슬라_KR.txt'},\n",
       "  {'source': 'data\\\\테슬라_KR.txt'}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings_huggingface = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=korean_docs,\n",
    "    embedding=embeddings_huggingface,\n",
    "    collection_name = \"db_korean_cosine\",\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}, #12, ip, cosine\n",
    ")\n",
    "\n",
    "chroma_db.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색결과\n",
      " - 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 [출처: data\\리비안_KR.txt]\n",
      " - .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 [출처: data\\리비안_KR.txt]\n"
     ]
    }
   ],
   "source": [
    "chroma_k_retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_k_retriever.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색결과\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\" - {doc.page_content} [출처: {doc.metadata['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Score Threshold(기준 스코어 이상인 문서를 대상으로 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색결과\n",
      " - 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 (유사도: 0.6734)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "chroma_mmr = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 2,\n",
    "        \"score_threshold\": 0.6, # 유사도 임계값\n",
    "    },\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_mmr.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색결과\")\n",
    "for doc in retrieved_docs:\n",
    "    score = cosine_similarity(\n",
    "        [embeddings_huggingface.embed_query(query)],\n",
    "        [embeddings_huggingface.embed_query(doc.page_content)]\n",
    "    )[0][0]\n",
    "    print(f\" - {doc.page_content} (유사도: {score:.4f})\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색결과\n",
      " - 리비안은 MIT 박사 출신 RJ 스카린지가 2009년에 설립한 혁신적인 미국 전기차 제조업체입니다. 2011년부터 자율 전기차에 집중한 리비안은 2015년 대규모 투자를 통해 크게 성장하며 미시간과 베이 지역에 연구소를 설립했습니다. 주요 공급업체와의 접근성을 높이기 위해 본사를 미시간주 리보니아로 이전했습니다 (유사도: data\\리비안_KR.txt)\n",
      "--------------------------------------------------\n",
      " - .\n",
      "\n",
      "리비안의 초기 모델은 스포츠카 R1(원래 이름은 Avera)로, 2+2 좌석의 미드 엔진 하이브리드 쿠페로 피터 스티븐스가 디자인했습니다. 이 차는 쉽게 교체 가능한 본체 패널을 갖춘 모듈식 캡슐 구조를 특징으로 하며, 2013년 말에서 2014년 초 사이에 생산이 예상되었습니다 (유사도: data\\리비안_KR.txt)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chroma_metadata = chroma_db.as_retriever(\n",
    "    search_kwargs = {\n",
    "        \"k\": 2,\n",
    "        \"filter\": {\"source\": \"data\\\\리비안_KR.txt\"}, #메타데이터 필터링\n",
    "    }\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_metadata.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색결과\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\" - {doc.page_content} (유사도: {doc.metadata['source']})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 리비안은 언제 사업을 시작했나요?\n",
      "검색결과\n",
      " - 테슬라(Tesla, Inc.)는 텍사스주 오스틴에 본사를 둔 미국의 대표적인 전기차 제조업체입니다. 2003년 마틴 에버하드(CEO)와 마크 타페닝(CFO)에 의해 설립된 테슬라는 2004년 페이팔과 Zip2의 공동 창업자인 일론 머스크의 참여로 큰 전환점을 맞았습니다 (유사도: data\\테슬라_KR.txt)\n",
      "--------------------------------------------------\n",
      " - . 머스크는 최대 주주이자 회장으로서 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 유명한 물리학자이자 전기공학자인 니콜라 테슬라의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다 (유사도: data\\테슬라_KR.txt)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chroma_content = chroma_db.as_retriever(\n",
    "    search_kwargs = {\n",
    "        \"k\": 2,\n",
    "        \"where_document\": {\"$contains\": \"테슬라\"}, #메타데이터 필터링\n",
    "    }\n",
    ")\n",
    "\n",
    "query = \"리비안은 언제 사업을 시작했나요?\"\n",
    "retrieved_docs = chroma_content.invoke(query)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(\"검색결과\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\" - {doc.page_content} (유사도: {doc.metadata['source']})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 체인 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "# 문서 포맷터 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chain = retriever | format_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 체인 생성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_chain, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IloveKOSA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-env-QISotLL5-py3.11\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    history_langchain = []\n",
    "    for human, ai in history:\n",
    "        history_langchain.append(HumanMessage(content=human))\n",
    "        history_langchain.append(AIMessage(content=ai))\n",
    "\n",
    "    history_langchain.append(HumanMessage(content=message))\n",
    "\n",
    "    response = rag_chain.invoke(message)\n",
    "\n",
    "    final_answer = llm.invoke(\n",
    "        history_langchain[:-1] + [AIMessage(content=response)] + [HumanMessage(content=message)]\n",
    "    )\n",
    "    return final_answer.content\n",
    "\n",
    "demo = gr.ChatInterface(fn=answer_invoke, title=\"QA Bot\")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7864\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env-QISotLL5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
